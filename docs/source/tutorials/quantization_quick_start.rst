
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "tutorials/quantization_quick_start.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_tutorials_quantization_quick_start.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_tutorials_quantization_quick_start.py:


Quantization Quickstart
=======================

Quantization reduces model size and speeds up inference time by reducing the number of bits required to represent weights or activations.

In NNI, both post-training quantization algorithms and quantization-aware training algorithms are supported.
Here we use `QATQuantizer` as an example to show the usage of quantization in NNI.

.. GENERATED FROM PYTHON SOURCE LINES 12-17

Preparation
-----------

In this tutorial, we use a simple model and pre-train on MNIST dataset.
If you are familiar with defining a model and training in pytorch, you can skip directly to `Quantizing Model`_.

.. GENERATED FROM PYTHON SOURCE LINES 17-30

.. code-block:: default


    import time
    from typing import Callable, Union, Union

    import torch
    import torch.nn.functional as F
    from torch.optim import Optimizer, SGD
    from torch.utils.data import DataLoader
    from torch import Tensor

    from nni.common.types import SCHEDULER









.. GENERATED FROM PYTHON SOURCE LINES 31-32

Define the model

.. GENERATED FROM PYTHON SOURCE LINES 32-57

.. code-block:: default

    class Mnist(torch.nn.Module):
        def __init__(self):
            super().__init__()
            self.conv1 = torch.nn.Conv2d(1, 20, 5, 1)
            self.conv2 = torch.nn.Conv2d(20, 50, 5, 1)
            self.fc1 = torch.nn.Linear(4 * 4 * 50, 500)
            self.fc2 = torch.nn.Linear(500, 10)
            self.relu1 = torch.nn.ReLU6()
            self.relu2 = torch.nn.ReLU6()
            self.relu3 = torch.nn.ReLU6()
            self.max_pool1 = torch.nn.MaxPool2d(2, 2)
            self.max_pool2 = torch.nn.MaxPool2d(2, 2)
            self.batchnorm1 = torch.nn.BatchNorm2d(20)

        def forward(self, x):
            x = self.relu1(self.batchnorm1(self.conv1(x)))
            x = self.max_pool1(x)
            x = self.relu2(self.conv2(x))
            x = self.max_pool2(x)
            x = x.view(-1, 4 * 4 * 50)
            x = self.relu3(self.fc1(x))
            x = self.fc2(x)
            return F.log_softmax(x, dim=1)









.. GENERATED FROM PYTHON SOURCE LINES 58-59

Create training and evaluation dataloader

.. GENERATED FROM PYTHON SOURCE LINES 59-72

.. code-block:: default

    from torch.utils.data import DataLoader
    from torchvision import transforms
    from torchvision.datasets import MNIST

    MNIST(root='data/mnist', train=True, download=True)
    MNIST(root='data/mnist', train=False, download=True)
    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])
    mnist_train = MNIST(root='data/mnist', train=True, transform=transform)
    train_dataloader = DataLoader(mnist_train, batch_size=64)
    mnist_test = MNIST(root='data/mnist', train=False, transform=transform)
    test_dataloader = DataLoader(mnist_test, batch_size=1000)






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz
    Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/mnist/MNIST/raw/train-images-idx3-ubyte.gz
      0%|          | 0/9912422 [00:00<?, ?it/s]      1%|          | 77824/9912422 [00:00<00:15, 626382.88it/s]      2%|2         | 234496/9912422 [00:00<00:08, 1124933.24it/s]      6%|6         | 612352/9912422 [00:00<00:04, 2267848.40it/s]     18%|#7        | 1745920/9912422 [00:00<00:01, 5712084.18it/s]     49%|####9     | 4903936/9912422 [00:00<00:00, 14820286.93it/s]     99%|#########9| 9857024/9912422 [00:00<00:00, 26393493.96it/s]    9913344it [00:00, 15803494.36it/s]                             
    Extracting data/mnist/MNIST/raw/train-images-idx3-ubyte.gz to data/mnist/MNIST/raw

    Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz
    Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz
      0%|          | 0/28881 [00:00<?, ?it/s]    29696it [00:00, 5413275.31it/s]          
    Extracting data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz to data/mnist/MNIST/raw

    Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz
    Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz
      0%|          | 0/1648877 [00:00<?, ?it/s]      5%|5         | 82944/1648877 [00:00<00:02, 674857.37it/s]     16%|#5        | 260096/1648877 [00:00<00:01, 1262964.51it/s]     44%|####3     | 718848/1648877 [00:00<00:00, 2705964.60it/s]    1649664it [00:00, 4108118.05it/s]                            
    Extracting data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to data/mnist/MNIST/raw

    Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz
    Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz
      0%|          | 0/4542 [00:00<?, ?it/s]    5120it [00:00, 29177766.96it/s]         
    Extracting data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/mnist/MNIST/raw





.. GENERATED FROM PYTHON SOURCE LINES 73-74

Define training and evaluation functions

.. GENERATED FROM PYTHON SOURCE LINES 74-118

.. code-block:: default

    device = "cuda:0" if torch.cuda.is_available() else "cpu"


    def training_step(batch, model) -> Tensor:
        x, y = batch[0].to(device), batch[1].to(device)
        logits = model(x)
        loss: torch.Tensor = F.nll_loss(logits, y)
        return loss


    def training_model(model: torch.nn.Module, optimizer: Optimizer, training_step: Callable, scheduler: Union[SCHEDULER, None] = None,
                       max_steps: Union[int, None] = None, max_epochs: Union[int, None] = None):
        model.train()
        max_epochs = max_epochs if max_epochs else 1 if max_steps is None else 100
        current_steps = 0

        # training
        for epoch in range(max_epochs):
            print(f'Epoch {epoch} start!')
            for batch in train_dataloader:
                optimizer.zero_grad()
                loss = training_step(batch, model)
                loss.backward()
                optimizer.step()
                current_steps += 1
                if max_steps and current_steps == max_steps:
                    return
            if scheduler is not None:
                scheduler.step()


    def evaluating_model(model: torch.nn.Module):
        model.eval()
        # testing
        correct = 0
        with torch.no_grad():
            for x, y in test_dataloader:
                x, y = x.to(device), y.to(device)
                logits = model(x)
                preds = torch.argmax(logits, dim=1)
                correct += preds.eq(y.view_as(preds)).sum().item()
        return correct / len(mnist_test)









.. GENERATED FROM PYTHON SOURCE LINES 119-120

Pre-train and evaluate the model on MNIST dataset

.. GENERATED FROM PYTHON SOURCE LINES 120-131

.. code-block:: default

    model = Mnist().to(device)
    optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)

    start = time.time()
    training_model(model, optimizer, training_step, None, None, 5)
    print(f'pure training 5 epochs: {time.time() - start}s')
    start = time.time()
    acc = evaluating_model(model)
    print(f'pure evaluating: {time.time() - start}s    Acc.: {acc}')






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Epoch 0 start!
    Epoch 1 start!
    Epoch 2 start!
    Epoch 3 start!
    Epoch 4 start!
    pure training 5 epochs: 70.65944242477417s
    pure evaluating: 1.637345314025879s    Acc.: 0.9901




.. GENERATED FROM PYTHON SOURCE LINES 132-137

Quantizing Model
----------------

Initialize a `config_list`.
Detailed about how to write ``config_list`` please refer :doc:`Config Specification <../compression_preview/config_list>`.

.. GENERATED FROM PYTHON SOURCE LINES 137-171

.. code-block:: default


    import nni
    from nni.contrib.compression.quantization import QATQuantizer
    from nni.contrib.compression.utils import TorchEvaluator


    optimizer = nni.trace(SGD)(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)
    evaluator = TorchEvaluator(training_model, optimizer, training_step)  # type: ignore

    config_list = [{
        'op_names': ['conv1', 'conv2', 'fc1', 'fc2'],
        'target_names': ['_input_', 'weight', '_output_'],
        'quant_dtype': 'int8',
        'quant_scheme': 'affine',
        'granularity': 'default',
    },{
        'op_names': ['relu1', 'relu2', 'relu3'],
        'target_names': ['_output_'],
        'quant_dtype': 'int8',
        'quant_scheme': 'affine',
        'granularity': 'default',
    }]

    quantizer = QATQuantizer(model, config_list, evaluator, len(train_dataloader))
    real_input = next(iter(train_dataloader))[0].to(device)
    quantizer.track_forward(real_input)

    start = time.time()
    _, calibration_config = quantizer.compress(None, max_epochs=5)
    print(f'pure training 5 epochs: {time.time() - start}s')

    print(calibration_config)
    start = time.time()
    acc = evaluating_model(model)
    print(f'quantization evaluating: {time.time() - start}s    Acc.: {acc}')



.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Epoch 0 start!
    Epoch 1 start!
    Epoch 2 start!
    Epoch 3 start!
    Epoch 4 start!
    pure training 5 epochs: 109.3075304031372s
    defaultdict(<class 'dict'>, {'fc1': {'weight': {'scale': tensor(0.0008), 'zero_point': tensor(18.), 'quant_dtype': 'int8', 'quant_scheme': 'affine', 'quant_bits': 8, 'tracked_max': tensor(0.0905), 'tracked_min': tensor(-0.1196)}, '_input_0': {'scale': tensor(0.0236), 'zero_point': tensor(-127.), 'quant_dtype': 'int8', 'quant_scheme': 'affine', 'quant_bits': 8, 'tracked_max': tensor(6.), 'tracked_min': tensor(0.)}, '_output_0': {'scale': tensor(0.0697), 'zero_point': tensor(-3.), 'quant_dtype': 'int8', 'quant_scheme': 'affine', 'quant_bits': 8, 'tracked_max': tensor(9.0455), 'tracked_min': tensor(-8.6706)}}, 'conv1': {'weight': {'scale': tensor(0.0026), 'zero_point': tensor(-10.), 'quant_dtype': 'int8', 'quant_scheme': 'affine', 'quant_bits': 8, 'tracked_max': tensor(0.3575), 'tracked_min': tensor(-0.3053)}, '_input_0': {'scale': tensor(0.0128), 'zero_point': tensor(-94.), 'quant_dtype': 'int8', 'quant_scheme': 'affine', 'quant_bits': 8, 'tracked_max': tensor(2.8215), 'tracked_min': tensor(-0.4242)}, '_output_0': {'scale': tensor(0.0307), 'zero_point': tensor(6.), 'quant_dtype': 'int8', 'quant_scheme': 'affine', 'quant_bits': 8, 'tracked_max': tensor(3.7238), 'tracked_min': tensor(-4.0632)}}, 'fc2': {'weight': {'scale': tensor(0.0021), 'zero_point': tensor(5.), 'quant_dtype': 'int8', 'quant_scheme': 'affine', 'quant_bits': 8, 'tracked_max': tensor(0.2537), 'tracked_min': tensor(-0.2751)}, '_input_0': {'scale': tensor(0.0236), 'zero_point': tensor(-127.), 'quant_dtype': 'int8', 'quant_scheme': 'affine', 'quant_bits': 8, 'tracked_max': tensor(6.), 'tracked_min': tensor(0.)}, '_output_0': {'scale': tensor(0.1495), 'zero_point': tensor(-38.), 'quant_dtype': 'int8', 'quant_scheme': 'affine', 'quant_bits': 8, 'tracked_max': tensor(24.6820), 'tracked_min': tensor(-13.2974)}}, 'conv2': {'weight': {'scale': tensor(0.0013), 'zero_point': tensor(-29.), 'quant_dtype': 'int8', 'quant_scheme': 'affine', 'quant_bits': 8, 'tracked_max': tensor(0.2035), 'tracked_min': tensor(-0.1277)}, '_input_0': {'scale': tensor(0.0236), 'zero_point': tensor(-127.), 'quant_dtype': 'int8', 'quant_scheme': 'affine', 'quant_bits': 8, 'tracked_max': tensor(6.0000), 'tracked_min': tensor(0.)}, '_output_0': {'scale': tensor(0.0969), 'zero_point': tensor(-6.), 'quant_dtype': 'int8', 'quant_scheme': 'affine', 'quant_bits': 8, 'tracked_max': tensor(12.8502), 'tracked_min': tensor(-11.7572)}}, 'relu3': {'_output_0': {'scale': tensor(0.0236), 'zero_point': tensor(-127.), 'quant_dtype': 'int8', 'quant_scheme': 'affine', 'quant_bits': 8, 'tracked_max': tensor(6.), 'tracked_min': tensor(0.)}}, 'relu2': {'_output_0': {'scale': tensor(0.0236), 'zero_point': tensor(-127.), 'quant_dtype': 'int8', 'quant_scheme': 'affine', 'quant_bits': 8, 'tracked_max': tensor(6.), 'tracked_min': tensor(0.)}}, 'relu1': {'_output_0': {'scale': tensor(0.0236), 'zero_point': tensor(-127.), 'quant_dtype': 'int8', 'quant_scheme': 'affine', 'quant_bits': 8, 'tracked_max': tensor(6.0000), 'tracked_min': tensor(0.)}}})
    quantization evaluating: 1.6686482429504395s    Acc.: 0.9918





.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 3 minutes  6.540 seconds)


.. _sphx_glr_download_tutorials_quantization_quick_start.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example


    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: quantization_quick_start.py <quantization_quick_start.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: quantization_quick_start.ipynb <quantization_quick_start.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
